{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qSxBuOOm0b4K"
   },
   "outputs": [],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "#import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (34, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yE5RTJq21ECP",
    "outputId": "cb0a729d-073a-46a9-fa65-24b46647038a"
   },
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()#기본으로 제공되는 얼굴인식모델\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')#얼굴 랜드마크(68개지점 탐지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 26, 34, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 34, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 17, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               786944    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('models/eyemodel.h5')# 과거 학습시킨모델\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PGI_zV7Z1Qwr"
   },
   "outputs": [],
   "source": [
    "def crop_eye(img, eye_points):#눈 위치 찾음\n",
    "    x1, y1 = np.amin(eye_points, axis=0)#수평방향중 최소 x,y\n",
    "    x2, y2 = np.amax(eye_points, axis=0)#수평방향중 최대 x,y\n",
    "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2 #눈 중심\n",
    "\n",
    "    w = (x2 - x1) * 1.2\n",
    "    h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "    margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "    min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "    max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "    eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "    eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "    return eye_img, eye_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CDLspG6r3SL_",
    "outputId": "12c39d69-4723-4bce-88e7-a636bd64d467"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-8f21331f07ce>:14: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "eye_q = np.zeros(50, dtype = int)#큐 크기 50\n",
    "eye_q = eye_q.tolist()\n",
    "state_threshold = 0.3#눈을 감았다고 판단하는 임계치\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img_ori = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "    img = img_ori.copy()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        shapes = predictor(gray, face)\n",
    "        shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "        eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "        eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "        eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "        eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "        eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "\n",
    "        eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "        eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "        pred_l = model.predict(eye_input_l)\n",
    "        pred_r = model.predict(eye_input_r)\n",
    "\n",
    "        # visualize\n",
    "        state_l = 'O' if pred_l > 0.3 else '-'# 'O':눈을 뜬 경우/ '-':눈을 감은 경우\n",
    "        state_r = 'O' if pred_r > 0.3 else '-'\n",
    "\n",
    "     \n",
    "\n",
    "        # perclos\n",
    "        if(pred_l<0.3 and  pred_r<0.3): #양 눈은 감았다고 판단한 경우\n",
    "            flag=1\n",
    "        else: # 양 눈은 떴다고 판단한 경우\n",
    "            flag=0\n",
    "        eye_q = eye_q[1:len(eye_q)] + [flag] # queue에 flag값 삽입\n",
    "\n",
    "        perclos = ((sum(eye_q) / len(eye_q)) * 100)#perclos계산 ((눈을 감은 누적된 시간/측정시간)x100)\n",
    "\n",
    "        if perclos >= 40:#눈을 감은 누적시간 판단기준 40\n",
    "            cv2.putText(img, \"Wake up!!\",(100,200), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)#졸음으로 판단되면 Wake up 경고 메세지 출력\n",
    "            #winsound.PlaySound(\"*\", winsound.SND_ALIAS)# 소리경고\n",
    "          \n",
    "        cv2.putText(img, \"Perclos:%.1f\"%perclos,(30,50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)#현재 perclos 수치 띄우기\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255, 255, 255), thickness=2)# 왼쪽 눈 영역 박스 씌우기\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255, 255, 255), thickness=2)# 오른쪽 눈 영역 박스 씌우기\n",
    "\n",
    "        cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)# 현재 왼쪽 눈 상태를 나타냄\n",
    "        cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)# 현재 오른쪽 눈 상태를 나타냄\n",
    "\n",
    "    cv2.imshow('result',img)\n",
    "    \n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "saIx_aYE4HEt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "run.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
